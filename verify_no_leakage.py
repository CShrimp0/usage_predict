"""
ç»ˆæžæ•°æ®æ³„éœ²éªŒè¯ - æ¨¡æ‹Ÿæ•°æ®é›†åˆ’åˆ†è¿‡ç¨‹ï¼ŒéªŒè¯æ— é‡å 

è¿™ä¸ªè„šæœ¬ä¼šï¼š
1. è¯»å–å®Œæ•´çš„æ•°æ®é›†é…ç½®
2. ä½¿ç”¨ç›¸åŒçš„å‚æ•°é‡æ–°æ‰§è¡Œæ•°æ®åˆ’åˆ†
3. éªŒè¯è®­ç»ƒé›†ã€éªŒè¯é›†ã€æµ‹è¯•é›†çš„å—è¯•è€…IDå®Œå…¨ä¸é‡å 
"""
import sys
import json
from pathlib import Path
from collections import defaultdict

# å¯¼å…¥æ•°æ®é›†åŠ è½½æ¨¡å—
sys.path.insert(0, '/home/szdx/LNX/usage_predict')
from dataset import stratified_split_by_age
import pandas as pd


def load_age_dict(excel_path):
    """ä»ŽExcelåŠ è½½å¹´é¾„å­—å…¸"""
    df = pd.read_excel(excel_path)
    
    age_dict = {}
    healthy_df = df[['Healthy', 'Unnamed: 1']].copy()
    healthy_df.columns = ['Number', 'Age']
    healthy_df = healthy_df[1:].dropna()
    
    for _, row in healthy_df.iterrows():
        try:
            subject_id = str(int(float(row['Number'])))
            age = float(row['Age'])
            age_dict[subject_id] = age
        except (ValueError, TypeError):
            continue
    
    return age_dict


def get_subject_images(image_dir, age_dict, min_age=0, max_age=100):
    """èŽ·å–ç¬¦åˆå¹´é¾„èŒƒå›´çš„å—è¯•è€…åŠå…¶å›¾åƒ"""
    image_dir = Path(image_dir)
    all_image_paths = sorted(list(image_dir.glob('*.png')) + list(image_dir.glob('*.jpg')))
    
    subject_images = defaultdict(list)
    for img_path in all_image_paths:
        parts = img_path.stem.split('_')
        if len(parts) >= 2:
            subject_id = parts[1]
            if subject_id in age_dict:
                subject_images[subject_id].append(str(img_path))
    
    # å¹´é¾„è¿‡æ»¤
    filtered_subjects = []
    for subject_id in subject_images.keys():
        age = age_dict[subject_id]
        if min_age <= age <= max_age:
            filtered_subjects.append(subject_id)
    
    return filtered_subjects, subject_images


def verify_no_overlap(result_dir):
    """
    éªŒè¯æ•°æ®é›†åˆ’åˆ†æ— é‡å 
    
    é€šè¿‡é‡æ–°æ‰§è¡Œæ•°æ®åˆ’åˆ†é€»è¾‘ï¼Œç¡®è®¤è®­ç»ƒé›†ã€éªŒè¯é›†ã€æµ‹è¯•é›†çš„å—è¯•è€…IDå®Œå…¨ä¸é‡å 
    """
    result_dir = Path(result_dir)
    
    # è¯»å–é…ç½®
    with open(result_dir / "test_metrics.json", 'r') as f:
        metrics = json.load(f)
    
    checkpoint_path = Path(metrics['evaluation_info']['checkpoint_path'])
    config_file = checkpoint_path.parent / "config.json"
    
    with open(config_file, 'r') as f:
        config = json.load(f)
    
    print("=" * 100)
    print("ðŸ” ç»ˆæžæ•°æ®æ³„éœ²éªŒè¯ - é‡æ–°æ‰§è¡Œæ•°æ®åˆ’åˆ†")
    print("=" * 100)
    
    print(f"\nðŸ“‹ ä½¿ç”¨çš„é…ç½®:")
    print(f"   - å›¾åƒç›®å½•: {config['dataset']['image_dir']}")
    print(f"   - Excelæ–‡ä»¶: {config['dataset']['excel_path']}")
    print(f"   - æµ‹è¯•é›†æ¯”ä¾‹: {config['dataset']['test_size']}")
    print(f"   - éªŒè¯é›†æ¯”ä¾‹: {config['dataset']['val_size']}")
    print(f"   - éšæœºç§å­: {config['dataset']['random_seed']}")
    print(f"   - å¹´é¾„åˆ†å±‚: {config['dataset']['use_age_stratify']}")
    print(f"   - å¹´é¾„åˆ†ç»„å®½åº¦: {config['dataset']['age_bin_width']}")
    
    # è¯»å–å¹´é¾„æ•°æ®
    print(f"\nðŸ“Š åŠ è½½æ•°æ®...")
    age_dict = load_age_dict(config['dataset']['excel_path'])
    print(f"   - æ€»å—è¯•è€…æ•° (Excel): {len(age_dict)}")
    
    # èŽ·å–ç¬¦åˆå¹´é¾„èŒƒå›´çš„å—è¯•è€…
    # ä»Žmetricsä¸­èŽ·å–å¹´é¾„èŒƒå›´
    age_range_str = metrics['dataset_config'].get('age_range', '0-100')
    if '-' in age_range_str:
        min_age, max_age = map(float, age_range_str.split('-'))
    else:
        min_age, max_age = 0, 100
    
    print(f"   - å¹´é¾„èŒƒå›´é™åˆ¶: {min_age}-{max_age} å²")
    
    all_subjects, subject_images = get_subject_images(
        config['dataset']['image_dir'], 
        age_dict, 
        min_age, 
        max_age
    )
    
    print(f"   - ç¬¦åˆå¹´é¾„èŒƒå›´çš„å—è¯•è€…: {len(all_subjects)}")
    
    # é‡æ–°æ‰§è¡Œæ•°æ®åˆ’åˆ†
    print(f"\nðŸ”„ é‡æ–°æ‰§è¡Œæ•°æ®åˆ’åˆ†...")
    
    if config['dataset']['use_age_stratify']:
        train_subjects, val_subjects, test_subjects = stratified_split_by_age(
            all_subjects,
            age_dict,
            test_size=config['dataset']['test_size'],
            val_size=config['dataset']['val_size'],
            random_state=config['dataset']['random_seed'],
            bin_width=config['dataset']['age_bin_width']
        )
    else:
        from sklearn.model_selection import train_test_split
        train_val_subjects, test_subjects = train_test_split(
            all_subjects,
            test_size=config['dataset']['test_size'],
            random_state=config['dataset']['random_seed'],
            shuffle=True
        )
        train_subjects, val_subjects = train_test_split(
            train_val_subjects,
            test_size=config['dataset']['val_size'],
            random_state=config['dataset']['random_seed'],
            shuffle=True
        )
    
    print(f"\nðŸ“Š åˆ’åˆ†ç»“æžœ:")
    print(f"   - è®­ç»ƒé›†å—è¯•è€…: {len(train_subjects)}")
    print(f"   - éªŒè¯é›†å—è¯•è€…: {len(val_subjects)}")
    print(f"   - æµ‹è¯•é›†å—è¯•è€…: {len(test_subjects)}")
    print(f"   - æ€»è®¡: {len(train_subjects) + len(val_subjects) + len(test_subjects)}")
    
    # éªŒè¯ä¸Žé…ç½®ä¸€è‡´
    print(f"\nâœ… ä¸Žè®­ç»ƒé…ç½®å¯¹æ¯”:")
    train_match = len(train_subjects) == config['dataset']['train_subjects']
    val_match = len(val_subjects) == config['dataset']['val_subjects']
    test_match = len(test_subjects) == config['dataset']['test_subjects']
    
    print(f"   - è®­ç»ƒé›†: {len(train_subjects)} vs {config['dataset']['train_subjects']} {'âœ…' if train_match else 'âŒ'}")
    print(f"   - éªŒè¯é›†: {len(val_subjects)} vs {config['dataset']['val_subjects']} {'âœ…' if val_match else 'âŒ'}")
    print(f"   - æµ‹è¯•é›†: {len(test_subjects)} vs {config['dataset']['test_subjects']} {'âœ…' if test_match else 'âŒ'}")
    
    # æ ¸å¿ƒéªŒè¯ï¼šæ£€æŸ¥é‡å 
    print(f"\n" + "=" * 100)
    print(f"ðŸ” æ ¸å¿ƒéªŒè¯: æ£€æŸ¥å—è¯•è€…IDé‡å ")
    print(f"=" * 100)
    
    train_set = set(train_subjects)
    val_set = set(val_subjects)
    test_set = set(test_subjects)
    
    # æ£€æŸ¥ä¸¤ä¸¤ä¹‹é—´çš„é‡å 
    train_val_overlap = train_set & val_set
    train_test_overlap = train_set & test_set
    val_test_overlap = val_set & test_set
    
    print(f"\nðŸ“Š é‡å æ£€æŸ¥:")
    print(f"   - è®­ç»ƒé›† âˆ© éªŒè¯é›†: {len(train_val_overlap)} ä¸ªé‡å å—è¯•è€…")
    if train_val_overlap:
        print(f"      âŒ å‘çŽ°é‡å : {sorted(list(train_val_overlap))[:10]}")
    else:
        print(f"      âœ… æ— é‡å ")
    
    print(f"   - è®­ç»ƒé›† âˆ© æµ‹è¯•é›†: {len(train_test_overlap)} ä¸ªé‡å å—è¯•è€…")
    if train_test_overlap:
        print(f"      âŒ å‘çŽ°é‡å : {sorted(list(train_test_overlap))[:10]}")
    else:
        print(f"      âœ… æ— é‡å ")
    
    print(f"   - éªŒè¯é›† âˆ© æµ‹è¯•é›†: {len(val_test_overlap)} ä¸ªé‡å å—è¯•è€…")
    if val_test_overlap:
        print(f"      âŒ å‘çŽ°é‡å : {sorted(list(val_test_overlap))[:10]}")
    else:
        print(f"      âœ… æ— é‡å ")
    
    # æ£€æŸ¥å¹¶é›†
    all_split_subjects = train_set | val_set | test_set
    print(f"\nðŸ“Š å®Œæ•´æ€§æ£€æŸ¥:")
    print(f"   - è®­ç»ƒâˆªéªŒè¯âˆªæµ‹è¯•: {len(all_split_subjects)} ä¸ªå—è¯•è€…")
    print(f"   - åŽŸå§‹å—è¯•è€…æ•°: {len(all_subjects)}")
    
    if len(all_split_subjects) == len(all_subjects):
        print(f"   âœ… æ‰€æœ‰å—è¯•è€…éƒ½è¢«åˆ†é…åˆ°æŸä¸ªé›†åˆ")
    else:
        missing = set(all_subjects) - all_split_subjects
        print(f"   âš ï¸ æœ‰ {len(missing)} ä¸ªå—è¯•è€…æœªè¢«åˆ†é…")
        if missing:
            print(f"      æœªåˆ†é…çš„å—è¯•è€…: {sorted(list(missing))[:10]}")
    
    # è¯»å–å®žé™…æµ‹è¯•é›†é¢„æµ‹ç»“æžœï¼ŒéªŒè¯æµ‹è¯•é›†å—è¯•è€…ID
    with open(result_dir / "predictions.json", 'r') as f:
        pred_data = json.load(f)
    
    actual_test_subjects = set()
    for filename in pred_data['filenames']:
        parts = Path(filename).stem.split('_')
        if len(parts) >= 2:
            actual_test_subjects.add(parts[1])
    
    print(f"\nðŸ“Š æµ‹è¯•é›†éªŒè¯:")
    print(f"   - é‡æ–°åˆ’åˆ†çš„æµ‹è¯•é›†: {len(test_set)} ä¸ªå—è¯•è€…")
    print(f"   - å®žé™…è¯„ä¼°çš„æµ‹è¯•é›†: {len(actual_test_subjects)} ä¸ªå—è¯•è€…")
    
    # æ£€æŸ¥æµ‹è¯•é›†æ˜¯å¦å®Œå…¨ä¸€è‡´
    test_match_set = test_set == actual_test_subjects
    test_extra = actual_test_subjects - test_set
    test_missing = test_set - actual_test_subjects
    
    if test_match_set:
        print(f"   âœ… æµ‹è¯•é›†å—è¯•è€…å®Œå…¨ä¸€è‡´")
    else:
        print(f"   âš ï¸ æµ‹è¯•é›†å—è¯•è€…ä¸å®Œå…¨ä¸€è‡´")
        if test_extra:
            print(f"      å¤šå‡ºçš„å—è¯•è€…: {sorted(list(test_extra))}")
        if test_missing:
            print(f"      ç¼ºå¤±çš„å—è¯•è€…: {sorted(list(test_missing))}")
    
    # æ˜¾ç¤ºæµ‹è¯•é›†å—è¯•è€…åˆ—è¡¨å¯¹æ¯”
    print(f"\nðŸ“ æµ‹è¯•é›†å—è¯•è€…IDå¯¹æ¯”:")
    print(f"   é‡æ–°åˆ’åˆ†: {sorted(test_set)}")
    print(f"   å®žé™…è¯„ä¼°: {sorted(actual_test_subjects)}")
    
    # æœ€ç»ˆç»“è®º
    print(f"\n" + "=" * 100)
    print(f"ðŸ“‹ æœ€ç»ˆéªŒè¯ç»“è®º:")
    print(f"=" * 100)
    
    all_checks = [
        ("è®­ç»ƒé›†ä¸ŽéªŒè¯é›†æ— é‡å ", len(train_val_overlap) == 0),
        ("è®­ç»ƒé›†ä¸Žæµ‹è¯•é›†æ— é‡å ", len(train_test_overlap) == 0),
        ("éªŒè¯é›†ä¸Žæµ‹è¯•é›†æ— é‡å ", len(val_test_overlap) == 0),
        ("å—è¯•è€…å®Œæ•´è¦†ç›–", len(all_split_subjects) == len(all_subjects)),
        ("æµ‹è¯•é›†å—è¯•è€…ä¸€è‡´", test_match_set),
        ("å—è¯•è€…æ•°é‡åŒ¹é…", train_match and val_match and test_match)
    ]
    
    all_passed = all(check[1] for check in all_checks)
    
    for check_name, passed in all_checks:
        status = "âœ… é€šè¿‡" if passed else "âŒ å¤±è´¥"
        print(f"   {status}: {check_name}")
    
    print(f"\n" + "=" * 100)
    if all_passed:
        print(f"ðŸŽ‰ éªŒè¯é€šè¿‡: æ•°æ®åˆ’åˆ†å®Œå…¨æ— é‡å !")
        print(f"\nðŸ“Œ éªŒè¯è¯æ®:")
        print(f"   1. é‡æ–°æ‰§è¡Œæ•°æ®åˆ’åˆ†é€»è¾‘ï¼Œä½¿ç”¨ç›¸åŒå‚æ•°ï¼ˆseed={config['dataset']['random_seed']}ï¼‰")
        print(f"   2. è®­ç»ƒé›†ã€éªŒè¯é›†ã€æµ‹è¯•é›†çš„å—è¯•è€…IDé›†åˆä¸¤ä¸¤æ— äº¤é›†")
        print(f"   3. ä¸‰ä¸ªé›†åˆçš„å¹¶é›†ç­‰äºŽå…¨éƒ¨å—è¯•è€…é›†åˆï¼ˆæ— é—æ¼ï¼‰")
        print(f"   4. é‡æ–°åˆ’åˆ†çš„æµ‹è¯•é›†ä¸Žå®žé™…è¯„ä¼°çš„æµ‹è¯•é›†å®Œå…¨ä¸€è‡´")
        print(f"   5. å—è¯•è€…æ•°é‡ä¸Žè®­ç»ƒé…ç½®å®Œå…¨åŒ¹é…")
        print(f"\nðŸ”’ æ•°å­¦è¯æ˜Ž:")
        print(f"   è®¾ Train={len(train_subjects)}, Val={len(val_subjects)}, Test={len(test_subjects)}")
        print(f"   Train âˆ© Val = âˆ… (ç©ºé›†)")
        print(f"   Train âˆ© Test = âˆ… (ç©ºé›†)")
        print(f"   Val âˆ© Test = âˆ… (ç©ºé›†)")
        print(f"   Train âˆª Val âˆª Test = All={len(all_subjects)}")
        print(f"   âˆ´ ä¸å­˜åœ¨ä»»ä½•å—è¯•è€…åŒæ—¶å‡ºçŽ°åœ¨è®­ç»ƒé›†å’Œæµ‹è¯•é›†")
        print(f"   âˆ´ ä¸å­˜åœ¨æ•°æ®æ³„éœ²")
    else:
        print(f"âš ï¸ éªŒè¯å¤±è´¥: å‘çŽ°é—®é¢˜!")
        failed_checks = [check for check in all_checks if not check[1]]
        for check_name, _ in failed_checks:
            print(f"   âŒ {check_name}")
    print(f"=" * 100)
    
    return all_passed


if __name__ == "__main__":
    if len(sys.argv) > 1:
        result_dir = sys.argv[1]
    else:
        result_dir = "/home/szdx/LNX/usage_predict/evaluation_results/run_20260113_164941"
    
    verify_no_overlap(result_dir)
