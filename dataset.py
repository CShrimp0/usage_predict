"""
TAè¶…å£°å›¾åƒå¹´é¾„é¢„æµ‹æ•°æ®é›†åŠ è½½å™¨ï¼ˆä¼˜åŒ–ç‰ˆï¼‰

åŠŸèƒ½ç‰¹æ€§ï¼š
- æ”¯æŒå¯é…ç½®çš„å›¾åƒå°ºå¯¸ï¼ˆ224Ã—224, 256Ã—256ç­‰ï¼‰
- æ”¯æŒæŒ‰å—è¯•è€…IDåˆ’åˆ†ï¼ˆé˜²æ­¢æ•°æ®æ³„éœ²ï¼‰
- æ”¯æŒæŒ‰å¹´é¾„åˆ†å±‚æŠ½æ ·ï¼ˆæé«˜æ³›åŒ–èƒ½åŠ›ï¼‰
- ç»Ÿä¸€çš„æ•°æ®å¢å¼ºé…ç½®
"""
import os
import pandas as pd
import numpy as np
from PIL import Image
import torch
from torch.utils.data import Dataset
from torchvision import transforms
from pathlib import Path
from sklearn.model_selection import train_test_split
from collections import defaultdict
import warnings


class TAUltrasoundAgeDataset(Dataset):
    """TAè¶…å£°å›¾åƒå¹´é¾„é¢„æµ‹æ•°æ®é›†"""
    
    def __init__(self, image_paths, ages, transform=None):
        """
        Args:
            image_paths: å›¾åƒæ–‡ä»¶è·¯å¾„åˆ—è¡¨
            ages: å¯¹åº”çš„å¹´é¾„æ ‡ç­¾åˆ—è¡¨
            transform: å›¾åƒå˜æ¢
        """
        self.image_paths = image_paths
        self.ages = ages
        self.transform = transform
        
    def __len__(self):
        return len(self.image_paths)
    
    def __getitem__(self, idx):
        # è¯»å–å›¾åƒï¼ˆå¤„ç†ä¸­æ–‡è·¯å¾„ï¼‰
        img_path = self.image_paths[idx]
        try:
            # ä½¿ç”¨PILè¯»å–ï¼Œæ”¯æŒä¸­æ–‡è·¯å¾„
            image = Image.open(img_path).convert('RGB')
        except Exception as e:
            print(f"Error loading {img_path}: {e}")
            # è¿”å›é»‘è‰²å›¾åƒä½œä¸ºå¤‡ç”¨
            image = Image.new('RGB', (224, 224), (0, 0, 0))
        
        age = self.ages[idx]
        
        if self.transform:
            image = self.transform(image)
        
        return image, torch.tensor(age, dtype=torch.float32)


def get_age_group(age, bin_width=10):
    """
    æ ¹æ®å¹´é¾„è·å–å¹´é¾„ç»„
    
    Args:
        age: å¹´é¾„å€¼
        bin_width: å¹´é¾„åˆ†ç»„å®½åº¦ï¼ˆé»˜è®¤10å²ï¼‰
    
    Returns:
        å¹´é¾„ç»„æ ‡ç­¾ï¼ˆå¦‚ "0-10", "10-20"ï¼‰
    """
    lower = int(age // bin_width) * bin_width
    upper = lower + bin_width
    return f"{lower}-{upper}"


def stratified_split_by_age(subject_ids, age_dict, test_size=0.2, val_size=0.1, 
                            random_state=42, bin_width=10):
    """
    æŒ‰å¹´é¾„åˆ†å±‚æŠ½æ ·åˆ’åˆ†æ•°æ®é›†
    
    Args:
        subject_ids: å—è¯•è€…IDåˆ—è¡¨
        age_dict: å—è¯•è€…IDåˆ°å¹´é¾„çš„æ˜ å°„ {subject_id: age}
        test_size: æµ‹è¯•é›†æ¯”ä¾‹
        val_size: éªŒè¯é›†æ¯”ä¾‹ï¼ˆä»è®­ç»ƒé›†ä¸­åˆ’åˆ†ï¼‰
        random_state: éšæœºç§å­
        bin_width: å¹´é¾„åˆ†ç»„å®½åº¦ï¼ˆé»˜è®¤10å²ï¼‰
    
    Returns:
        train_subjects, val_subjects, test_subjects: ä¸‰ä¸ªé›†åˆçš„å—è¯•è€…IDåˆ—è¡¨
    """
    # ä¸ºæ¯ä¸ªå—è¯•è€…åˆ†é…å¹´é¾„ç»„
    subject_age_groups = []
    valid_subjects = []
    
    for sid in subject_ids:
        if sid in age_dict:
            age = age_dict[sid]
            age_group = get_age_group(age, bin_width)
            subject_age_groups.append(age_group)
            valid_subjects.append(sid)
    
    # ç»Ÿè®¡æ¯ä¸ªå¹´é¾„ç»„çš„æ ·æœ¬æ•°
    age_group_counts = defaultdict(int)
    for ag in subject_age_groups:
        age_group_counts[ag] += 1
    
    print(f"\nğŸ“Š å¹´é¾„åˆ†å±‚ç»Ÿè®¡ï¼ˆæ¯{bin_width}å²ä¸€ç»„ï¼‰:")
    for age_group in sorted(age_group_counts.keys(), key=lambda x: int(x.split('-')[0])):
        count = age_group_counts[age_group]
        print(f"  {age_group}å²: {count} ä¸ªå—è¯•è€…")
    
    # é¦–å…ˆåˆ’åˆ†è®­ç»ƒ+éªŒè¯é›† vs æµ‹è¯•é›†ï¼ˆåˆ†å±‚æŠ½æ ·ï¼‰
    train_val_subjects, test_subjects, _, _ = train_test_split(
        valid_subjects,
        subject_age_groups,
        test_size=test_size,
        random_state=random_state,
        stratify=subject_age_groups
    )
    
    # å†ä»è®­ç»ƒ+éªŒè¯é›†ä¸­åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†ï¼ˆåˆ†å±‚æŠ½æ ·ï¼‰
    train_val_age_groups = [get_age_group(age_dict[sid], bin_width) for sid in train_val_subjects]
    
    # æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„æ ·æœ¬è¿›è¡Œåˆ†å±‚
    group_counts_trainval = defaultdict(int)
    for ag in train_val_age_groups:
        group_counts_trainval[ag] += 1
    
    # å¦‚æœæŸäº›å¹´é¾„ç»„æ ·æœ¬å¤ªå°‘ï¼Œæ— æ³•åˆ†å±‚ï¼Œåˆ™ä¸ä½¿ç”¨stratify
    min_samples_per_group = min(group_counts_trainval.values()) if group_counts_trainval else 0
    use_stratify_val = min_samples_per_group >= 2  # è‡³å°‘éœ€è¦2ä¸ªæ ·æœ¬æ‰èƒ½åˆ†å±‚
    
    if use_stratify_val:
        train_subjects, val_subjects, _, _ = train_test_split(
            train_val_subjects,
            train_val_age_groups,
            test_size=val_size,
            random_state=random_state,
            stratify=train_val_age_groups
        )
    else:
        warnings.warn(f"éªŒè¯é›†åˆ’åˆ†æ—¶æŸäº›å¹´é¾„ç»„æ ·æœ¬è¿‡å°‘ï¼ˆæœ€å°‘{min_samples_per_group}ä¸ªï¼‰ï¼Œå–æ¶ˆåˆ†å±‚æŠ½æ ·")
        train_subjects, val_subjects = train_test_split(
            train_val_subjects,
            test_size=val_size,
            random_state=random_state
        )
    
    return train_subjects, val_subjects, test_subjects


def load_dataset(image_dir, excel_path, test_size=0.2, val_size=0.1, random_state=42,
                image_size=224, use_age_stratify=False, age_bin_width=10):
    """
    åŠ è½½æ•°æ®é›†å¹¶åˆ’åˆ†è®­ç»ƒã€éªŒè¯ã€æµ‹è¯•é›†
    
    Args:
        image_dir: å›¾åƒæ–‡ä»¶å¤¹è·¯å¾„
        excel_path: Excelæ ‡ç­¾æ–‡ä»¶è·¯å¾„
        test_size: æµ‹è¯•é›†å æ€»æ•°æ®çš„æ¯”ä¾‹
        val_size: éªŒè¯é›†å è®­ç»ƒæ•°æ®çš„æ¯”ä¾‹
        random_state: éšæœºç§å­
        image_size: å›¾åƒresizeå°ºå¯¸ï¼ˆé»˜è®¤224ï¼‰
        use_age_stratify: æ˜¯å¦ä½¿ç”¨å¹´é¾„åˆ†å±‚æŠ½æ ·ï¼ˆé»˜è®¤Falseï¼‰
        age_bin_width: å¹´é¾„åˆ†ç»„å®½åº¦ï¼Œä»…åœ¨use_age_stratify=Trueæ—¶æœ‰æ•ˆï¼ˆé»˜è®¤10å²ï¼‰
    
    Returns:
        train_dataset, val_dataset, test_dataset: è®­ç»ƒé›†ã€éªŒè¯é›†ã€æµ‹è¯•é›†
    """
    # è¯»å–Excelæ ‡ç­¾æ–‡ä»¶
    df = pd.read_excel(excel_path)
    
    # å»ºç«‹å—è¯•è€…IDåˆ°å¹´é¾„çš„æ˜ å°„
    age_dict = {}
    
    # å¤„ç†Healthyåˆ—ï¼ˆç¬¬ä¸€ç»„æ•°æ®ï¼‰
    healthy_df = df[['Healthy', 'Unnamed: 1']].copy()
    healthy_df.columns = ['Number', 'Age']
    healthy_df = healthy_df[1:].dropna()  # è·³è¿‡æ ‡é¢˜è¡Œ
    
    for _, row in healthy_df.iterrows():
        try:
            subject_id = str(int(float(row['Number'])))
            age = float(row['Age'])
            age_dict[subject_id] = age
        except (ValueError, TypeError):
            continue
    
    # è·å–æ‰€æœ‰å›¾åƒè·¯å¾„
    image_dir = Path(image_dir)
    all_image_paths = sorted(list(image_dir.glob('*.png')) + list(image_dir.glob('*.jpg')))
    
    # æŒ‰å—è¯•è€…IDåˆ†ç»„å›¾åƒ
    subject_images = defaultdict(list)
    for img_path in all_image_paths:
        # ä»æ–‡ä»¶åä¸­æå–å—è¯•è€…IDï¼ˆæ ¼å¼: TAXX_ID_X.pngï¼‰
        parts = img_path.stem.split('_')
        if len(parts) >= 2:
            subject_id = parts[1]
            if subject_id in age_dict:
                subject_images[subject_id].append(str(img_path))
    
    # è·å–æ‰€æœ‰å—è¯•è€…ID
    all_subjects = list(subject_images.keys())
    
    # ç»Ÿè®¡ä¿¡æ¯
    total_subjects = len(all_subjects)
    total_images = sum(len(imgs) for imgs in subject_images.values())
    ages_list = [age_dict[sid] for sid in all_subjects]
    
    print(f"æ‰¾åˆ° {total_subjects} ä¸ªå—è¯•è€…ï¼Œå…± {total_images} å¼ å›¾åƒ")
    print(f"æ¯ä¸ªå—è¯•è€…å›¾åƒæ•°: å¹³å‡ {total_images/total_subjects:.2f}, "
          f"æœ€å°‘ {min(len(imgs) for imgs in subject_images.values())}, "
          f"æœ€å¤š {max(len(imgs) for imgs in subject_images.values())}")
    print(f"å¹´é¾„èŒƒå›´: {min(ages_list):.1f} - {max(ages_list):.1f} å²")
    print(f"å¹³å‡å¹´é¾„: {np.mean(ages_list):.1f} Â± {np.std(ages_list):.1f} å²")
    
    # åˆ’åˆ†æ•°æ®é›†
    if use_age_stratify:
        print(f"\nğŸ”’ ä½¿ç”¨æŒ‰å¹´é¾„åˆ†å±‚æŠ½æ ·åˆ’åˆ†æ•°æ®é›†ï¼ˆæ¯{age_bin_width}å²ä¸€ç»„ï¼‰...")
        train_subjects, val_subjects, test_subjects = stratified_split_by_age(
            all_subjects, age_dict, test_size, val_size, random_state, age_bin_width
        )
    else:
        print(f"\nğŸ”’ æŒ‰å—è¯•è€…IDåˆ’åˆ†æ•°æ®é›†ï¼ˆé˜²æ­¢æ•°æ®æ³„éœ²ï¼‰...")
        # ä¼ ç»Ÿçš„æŒ‰IDéšæœºåˆ’åˆ†
        train_val_subjects, test_subjects = train_test_split(
            all_subjects,
            test_size=test_size,
            random_state=random_state,
            shuffle=True
        )
        
        train_subjects, val_subjects = train_test_split(
            train_val_subjects,
            test_size=val_size,
            random_state=random_state,
            shuffle=True
        )
    
    print(f"\nå—è¯•è€…åˆ’åˆ†:")
    print(f"  è®­ç»ƒé›†å—è¯•è€…: {len(train_subjects)}")
    print(f"  éªŒè¯é›†å—è¯•è€…: {len(val_subjects)}")
    print(f"  æµ‹è¯•é›†å—è¯•è€…: {len(test_subjects)}")
    
    # æ”¶é›†æ¯ä¸ªé›†åˆçš„å›¾åƒå’Œæ ‡ç­¾
    train_paths, train_ages = [], []
    val_paths, val_ages = [], []
    test_paths, test_ages = [], []
    
    for sid in train_subjects:
        for img_path in subject_images[sid]:
            train_paths.append(img_path)
            train_ages.append(age_dict[sid])
    
    for sid in val_subjects:
        for img_path in subject_images[sid]:
            val_paths.append(img_path)
            val_ages.append(age_dict[sid])
    
    for sid in test_subjects:
        for img_path in subject_images[sid]:
            test_paths.append(img_path)
            test_ages.append(age_dict[sid])
    
    print(f"\næ•°æ®é›†åˆ’åˆ†:")
    print(f"  è®­ç»ƒé›†: {len(train_paths)} æ ·æœ¬ï¼Œå¹´é¾„ {np.mean(train_ages):.1f}Â±{np.std(train_ages):.1f} å²")
    print(f"  éªŒè¯é›†: {len(val_paths)} æ ·æœ¬ï¼Œå¹´é¾„ {np.mean(val_ages):.1f}Â±{np.std(val_ages):.1f} å²")
    print(f"  æµ‹è¯•é›†: {len(test_paths)} æ ·æœ¬ï¼Œå¹´é¾„ {np.mean(test_ages):.1f}Â±{np.std(test_ages):.1f} å²")
    
    # å®šä¹‰å›¾åƒå˜æ¢ï¼ˆæ”¯æŒå¯é…ç½®çš„å›¾åƒå°ºå¯¸ï¼‰
    print(f"\nä½¿ç”¨å›¾åƒå°ºå¯¸: {image_size}Ã—{image_size}")
    
    # è®­ç»ƒé›†å¢å¼º
    train_transform = transforms.Compose([
        transforms.Resize((image_size, image_size)),
        transforms.RandomRotation(degrees=10),
        transforms.ColorJitter(brightness=0.2, contrast=0.2),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                           std=[0.229, 0.224, 0.225])
    ])
    
    # éªŒè¯é›†å’Œæµ‹è¯•é›†ä¸å¢å¼º
    eval_transform = transforms.Compose([
        transforms.Resize((image_size, image_size)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                           std=[0.229, 0.224, 0.225])
    ])
    
    # åˆ›å»ºæ•°æ®é›†
    train_dataset = TAUltrasoundAgeDataset(train_paths, train_ages, train_transform)
    val_dataset = TAUltrasoundAgeDataset(val_paths, val_ages, eval_transform)
    test_dataset = TAUltrasoundAgeDataset(test_paths, test_ages, eval_transform)
    
    return train_dataset, val_dataset, test_dataset


def get_transform(image_size=224, is_train=True):
    """
    è·å–å›¾åƒå˜æ¢
    
    Args:
        image_size: å›¾åƒå°ºå¯¸
        is_train: æ˜¯å¦ä¸ºè®­ç»ƒæ¨¡å¼
    
    Returns:
        transform: torchvisionå˜æ¢
    """
    if is_train:
        return transforms.Compose([
            transforms.Resize((image_size, image_size)),
            transforms.RandomRotation(degrees=10),
            transforms.ColorJitter(brightness=0.2, contrast=0.2),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                               std=[0.229, 0.224, 0.225])
        ])
    else:
        return transforms.Compose([
            transforms.Resize((image_size, image_size)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                               std=[0.229, 0.224, 0.225])
        ])


# å‘åå…¼å®¹ï¼šä¿ç•™æ—§çš„æ¥å£
def load_dataset_old_interface(base_path, excel_path, test_size=0.2, val_size=0.1, random_state=42):
    """
    æ—§æ¥å£ï¼ˆå‘åå…¼å®¹ï¼‰ï¼Œé»˜è®¤ä½¿ç”¨224Ã—224ï¼Œä¸ä½¿ç”¨å¹´é¾„åˆ†å±‚
    """
    return load_dataset(
        image_dir=base_path,
        excel_path=excel_path,
        test_size=test_size,
        val_size=val_size,
        random_state=random_state,
        image_size=224,
        use_age_stratify=False
    )
